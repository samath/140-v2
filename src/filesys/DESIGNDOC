       	 +-------------------------+
		     | CS 140                  |
		     | PROJECT 4: FILE SYSTEMS |
		     | DESIGN DOCUMENT         |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Thomas Shepherd <shepert@stanford.edu>
Sam Keller <samath@stanford.edu>
Lawrence Xing <lxing@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

Thomas Shepherd: buffer cache
Sam Keller: indexed + extensible files
Lawrence Xing: subdirectories, syscalls 

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


Struct used to store synchronization data for managing writes and reads.

    struct file_synch_status
      {
        struct lock lock;
        unsigned writers_waiting;
        unsigned readersr_running;
        struct condition read_cond;
        struct condition write_cond;
      };

Replaced the unused space in inode_disk with a block table.  Deleted the 
start block_sector_t.

    struct inode_disk
      {
        off_t length;
        unsigned isdir;
        unsigned magic;
        block_sector_t blocks[TOTAL_BLOCKS];
      };

Constants defining the breakdown of the block table.  The maximum size + 
optimal distribution can be modified here.

    #define DIRECT_BLOCKS 64
    #define INDIRECT_BLOCKS 60
    #define DOUBLY_INDIRECT 1
    #define TOTAL_BLOCKS (DIRECT_BLOCKS + INDIRECT_BLOCKS + DOUBLY_INDIRECT)
    #define INDIRECT_SIZE (BLOCK_SECTOR_SIZE / sizeof(block_sector_t))
    #define MAX_SIZE (1 << 23)


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.


With the constants as defined above, the maximum supported file size is
    BLOCK_SECTOR_SIZE * (DIRECT_BLOCKS +
                         INDIRECT_BLOCKS * INDIRECT_SIZE +
                         DOUBLY_INDIRECT * INDIRECT_SIZE * INDIRECT_SIZE).
Filling in the values, this gives 24,128 blocks and 12,353,536 bytes.
This is > 12MB, which is significantly larger then the maximum size of 
  the file system.

The existing code assumes that INDIRECT_BLOCK = 1, but it could easily 
be modified to support much larger files.



---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.


Each file has a lock and some corresponding metadata stored along with 
  its entry in the file-map, which can be accessed using an inode*.

In a call to inode_write_at, the thread acquires the corresponding lock,
  and then checks if the write will require file extension.  If so, the 
  lock is held for the duration of the write, until all blocks are allocated,
  data is written, and the length & disk_inode are updated on disk.

Once all readers have completed, the process checks once more that extension
  is still necessary before proceeding to allocate blocks.

At any given time, this scheme ensures that at most one process is extending
  a file at the time.  Furthermore, no blocks are allocated until acquiring
  a file-specific lock and checking that extension is necessary.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.


Using the same file-specific lock as in the previous problem, a process that
  is extending a file will wait for all readers to complete.  Similarly, 
  once extension has started, no process can read from the file until it has
  completed.  This means that once the reading thread is able to reacquire 
  the lock, the write has been propagated to disk (or the buffer cache), and 
  so it is impossible to read incomplete data.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.




---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?


The inode is implemented using a multilevel index.
Given that a single full doubly indirect block supports files up to 
the maximum size of the file system, it is clear that we need at most 1;
however, it is impossible to support the full size without one, so 
(again using the constants above) we must have DOUBLY_INDIRECT = 1.

I distributed the remaining space in the disk_inode approximately evenly 
between direct blocks and indirect blocks.  Since we have a doubly 
indirect block, there is no space concern.  Using a balanced division 
allows efficient support for a range of files; this structure allows files
of size at most 32 kB to be represented without using indirect blocks ever.
By including a significant number of indirect blocks, this inode arrangement
can support files up to ~4MB without requiring the doubly indirect block.

Note that if this filesystem is being used for a specific purpose which 
expects files of a certain size to appear frequently, these numbers can be 
easily adjusted to optimize for these values.



			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

This is implemented in dir_lookup_recursive, which updates the
variable 'sector' repeatedly as elements of

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct cache_entry
{
  char data[BLOCK_SECTOR_SIZE];
  block_sector_t block_num;
  block_sector_t readahead;
  int handlers;
  bool metadata;
  int priority;
  bool dirty;
  struct block *fs;

  struct condition cond;
};

An entry in the buffer cache which contains a block worth of disk data and
metadata used for synchronization and eviction.

struct readahead_order
{
  block_sector_t block_num;
  struct block *fs;
  struct list_elem elem;
};

A pending disk IO order to read in a subsequent block by a background thread.

static struct cache_entry cache[CACHE_SIZE];

The actual cache in memory. We used an array because the cache is a fixed size.

static struct lock cache_lock;

A single lock for making changes to entries in the cache. This lock is not held
for any disk IO's.

static struct lock readahead_lock;
static struct condition readahead_wait;
static struct list readahead_list;

A list to hold read-ahead orders. Uses a lock and condition variable to avoid
busy waiting by the background thread.

static int clock_hand;

The clock_hand for the clock eviction algorithm.

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We implemented a clock algorithm to handle eviction. Each cache entry is
assigned a priority when it gets read in. Regular data is given a priority
of 1, while metadata is given a priority of 3. Each time the clock hand
reaches an entry, it decrements the priority. Once the priority reaches
0, it gets marked for eviction and flushed if necessary.

The eviction process will continue moving the clock_hand until it finds an
entry to evict. By assigning metadata a priority of 3, it will tend to stay in
the cache approximately 3 times longer than regular data. Anytime a cache
entry is accessed, its priority gets reset back to its original.

>> C3: Describe your implementation of write-behind.

Write-behind is implemented by flushing the cache only when a cache entry gets
evicted, or when the 30 second, flush-all timer has expired.

If an entry is marked for eviction, and it is dirty, the running thread must
flush it before loading in the new cache entry. The cache_flush_block function
gets called. This assumes the cache_lock is already held. If any other threads
are currently handling the entry, this thread will wait until they finish.

Once the block is not being used, the cache lock is released and it gets
written back to disk. Because the handlers value is greater than zero, no
other threads will be able to use this block until flushing is complete. The
block_num is immediately replaced by the new block_num to avoid race conditions
in search_cache.

If 30 seconds has expired, a background thread will flush all blocks in the
cache, regardless of how new they are. In this case, the blocks are not
replaced with new ones, but they are marked as no longer dirty.

>> C4: Describe your implementation of read-ahead.

When a regular disk block is first accessed, the block that follows the first
in memory is calculated. After the first block gets read in, the process
submits a read-ahead order to the read-ahead background thread. This background
thread maintains a list of all read-ahead orders and wakes up from a signal
by the calling process whenever an order gets added to the list.

The background thread then reads in the new block just like any other block
that gets read into the cache. The only difference is we do not trigger a
second read-ahead order if this call originated from a read-ahead order.

The advantage of this method is such that processes often read subsequent
blocks, so by loading in the next block in parallel with the thread, it will
hopefully already be read into the cache by the time it is needed.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

We used two techniques to help lock blocks.

First, the cache has a global cache_lock which is held throughout all cache
manipulations. This lock is only released during disk IO's. Each cache entry
has a condition variable so that any process waiting on that particular entry
may be signaled when it becomes available. Therefore, the global lock is also
released when a process is waiting for a particular cache entry.

Second, each cache entry keeps track of how many threads are currently handling
the entry. This is designated in 'handlers'. If handlers is greater than 0,
the process will have to wait for the other processess to finish before
accessing the block itself. The handlers value is maintained during disk IO's
and does not get decremented until we are done manipulating the cache entry.
At this time, we also signal any other processes waiting on the cache entry.

The eviction process must hold the cache lock and make sure that the block is
not currently being handled by another process. In this way, we do not mark an
active block for eviction. Nor can the block become active until eviction is
complete due to the lock.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

The question above describes the general synchronization techniques used
in caching. During eviction, the cache_lock is held preventing any new threads
from starting a cache access, and if the block is currently active by a
separate process, than it will not be evicted in the first place.

The cache lock gets released right before the flush disk IO begins, but the
handlers value is greater than 0, so no new processes will be able to access
the block until eviction is complete.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Any file workload that repeatedly uses the same blocks on disk will benefit
from buffer caching. This could include writing to a text file, where you
only have to write to cache.

Workloads benefit from read-ahead if they have subsequent block accesses.
Watching a movie could be one example where the next block of data is being
read in before it is needed by the media player.

Workloads benefit from write-behind if they are going to be making multiple
changes. For example a text document where the author keeps writing changes
to the same area of text. Each new write would not require a new disk IO,
rather the changes would go to cache and eventually be saved back to disk,
whether due to eviction or a flush timer.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
